{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partiționare\n",
    "\n",
    "La crearea unui RDD se poate specifica numărul de partiții\n",
    "<br>Numărul implicit este numărul de workers definit la crearea lui `SparkContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crearea unui `SparkContext` cu 2 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paralelizati lista primelor 1000000 numere intregi\n",
    "# A ="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizarea `getNumPartitions` pentru regăsirea numărului de partiții create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putem repartiționa _A_ în orice număr de partiții"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = A.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putem stabili numărul de partiții la crearea RDD-ului cu argumentul `numSlices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sc.parallelize(range(1000000),numSlices=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afisati numarul de partitii\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De ce sunt importante partițiile?\n",
    "\n",
    "* Definesc unitatea asupra căreia lucrează executorul\n",
    "* Ar trebui să existe tot atâtea partiții cât numărul de noduri worker\n",
    "* Partițiile mai mici pot permite mai mult paralelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repartiționare pentru Load Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presupunem că pornim cu 10 partiții, toate cu exact același număr de elemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=sc.parallelize(range(1000000)).map(lambda x:(x,x)).partitionBy(10)\n",
    "print(A.glom().map(len).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presupunem că dorim să folosim funcția **`filter()`** pentru a selecta o parte din elementele lui A.<br>\n",
    "În unele partiții pot rămâne mai multe elemente decât în altele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selectati 20% din elemente, pe baza unui filtru care retine doar numerele divizibile cu 5\n",
    "B=\n",
    "# Obtineti numarul de elemente din partitiile lui B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operațiile viitoare asupra lui B vor folosi doar 2 workers.<br>\n",
    "Celalți workers nu vor face nimic, deoarece partițiile lor sunt vide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pentru a corecta această situație trebuie să repartiționăm RDD-ul neechilibrat. <br>Un mod de a realiza acest lucru este să repartiționăm folosind o cheie nouă, cu ajutorul metodei `partitionBy()`\n",
    "\n",
    "* Metoda **`.partitionBy(k)`** așteaptă un RDD de forma **`(key,value)`**, unde cheile sunt întregi.\n",
    "* Partiționează RDD-ul în **`k`** partiții.\n",
    "* Elementul **`(key,value)`** este plasat în partiția **`key % k`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redistribuiți B în 10 partiții cu număr egal de elemente\n",
    "#C=\n",
    "#Obțineți numărul de elemente din partițiile lui C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observăm că **`C`** constă din doar 200,000 elemente din partiția neechilibrată **`B`** dar le distribuie în partiții egale de câte 20,000 elemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O altă abordare: utilizarea partiționării aleatoare cu ajutorul **`repartition(k)`**\n",
    "* Un **avantaj** al partiționării aleatoare este că aceasta nu necesită definirea unei chei.\n",
    "* Un **dezavantaj** al partitionării aleatoare este că nu există control asupra acesteia (nu putem stabili în ce partiții merg elementele)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=B.repartition(10)\n",
    "print(C.glom().map(len).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Glom()`\n",
    "* În general, Spark nu permite worker-ului să refere elemente specifice din RDD.\n",
    "* Aceasta poate fi o limitare majoră.\n",
    "\n",
    "#### `glom()` transformă fiecare partiție într-o listă de elemente.<br> Creează un RDD de liste, câte o listă pentru fiecare partiție.<br>Worker-ii pot referi elemente ale partiției prin indexul acestora, dar nu pot fi atribuite valori elementelor, RDD-ul fiind imutabil.\n",
    "\n",
    "* Considerăm **comanda folosită anterior pentru a număra elementele fiecărei partiții**: `print(C.glom().map(len).collect())`\n",
    "* Am folosit `glom()` ca să transformăm fiecare partiție într-o listă.\n",
    "* Am folosit `len` asupra fiecărei partiții pentru a obține lungimea listei - dimensiunea partiției.\n",
    "* Am aplicat `collect` pentru a colecta rezultatele și a le afișa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un exemplu mai complex\n",
    "Metoda `glom()` poate fi utilă în mai multe cazuri.\n",
    "<br>\n",
    "De exemplu, presupunem că dorim să obținem primul element, numărul de elemente și suma dintre primul și ultimul element din partițiile neechilibrate pe care le-am obținut din `A` în `B`. Dacă o partiție este vidă returnăm `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiți funcția ce returnează tuplul de 3 elemente cerut pentru fiecare partiție\n",
    "#def getPartitionInfo(P):\n",
    " \n",
    "#Apelați funcția pentru partițiile lui B și afișați rezultatul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
